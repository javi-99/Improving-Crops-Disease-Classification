{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import sys,os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import os.path\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"wheat_data/test_128\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms for the training and validation sets\n",
    "data_transforms ={ \"test_transforms\": transforms.Compose([#transforms.Resize(128),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root_clean = 'wheat_data/test_128/clean_imgs'\n",
    "test_root_blur = 'wheat_data/test_128/blur_imgs'\n",
    "test_root_deblur = 'wheat_data/test_128/deblur_imgs'\n",
    "test_root_spvd_deblur = 'wheat_data/test_128/deblur_spvd_imgs'\n",
    "\n",
    "\n",
    "\n",
    "dir_test = test_root_clean  # blur test\n",
    "dir_blur = test_root_blur   # blur test\n",
    "dir_deblur = test_root_deblur  # deblur test\n",
    "dir_deblur_spvd = test_root_spvd_deblur  # deblur test\n",
    "\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "test_data = datasets.ImageFolder(dir_test, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "test_data_blur = datasets.ImageFolder(dir_blur, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "test_data_deblur = datasets.ImageFolder(dir_deblur, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "test_data_deblur_spvd = datasets.ImageFolder(dir_deblur_spvd, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "clean_testloader = torch.utils.data.DataLoader(test_data, batch_size = 32)\n",
    "blur_testloader  = torch.utils.data.DataLoader(test_data_blur, batch_size = 32)\n",
    "deblur_testloader  = torch.utils.data.DataLoader(test_data_deblur, batch_size = 32)\n",
    "spvd_deblur_testloader  = torch.utils.data.DataLoader(test_data_deblur_spvd, batch_size = 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['healthy_wheat', 'leaf_rust', 'stem_rust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_path = 'trained_models/googlenet.pt'\n",
    "# Specify model architecture\n",
    "# Load the pretrained model from pytorch's library and stored it in model_transfer\n",
    "model_transfer = models.googlenet(pretrained=True)\n",
    "\n",
    "# Check if GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "    \n",
    "#print the model to see all the layers\n",
    "#print(model_transfer)\n",
    "\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad=True\n",
    "    \n",
    "# Define n_inputs takes the same number of inputs from pre-trained model\n",
    "n_inputs = model_transfer.fc.in_features #refer to the fully connected layer only\n",
    "\n",
    "# Add last linear layer (n_inputs -> 4 classes). In this case the ouput is 4 classes\n",
    "# New layer automatically has requires_grad = True\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "\n",
    "model_transfer.fc = last_layer\n",
    "\n",
    "# If GPU is available, move the model to GPU\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()\n",
    "  \n",
    "# Check to see the last layer produces the expected number of outputs\n",
    "print(model_transfer.fc.out_features)\n",
    "\n",
    "# Load the model that got the best validation accuracy\n",
    "model_transfer.load_state_dict(torch.load(trained_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "actual = []\n",
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model_transfer.eval() #set model into evaluation/testing mode. It turns of drop off layer\n",
    "    #Iterating over test data\n",
    "    for batch_idx, (data, target) in enumerate(loaders):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        actual.append(np.squeeze(target.cpu().numpy()))\n",
    "        predicted.append(np.squeeze(pred.cpu().numpy()))\n",
    "        \n",
    "        # compare predictions to \n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['healthy', 'leaf_rust', 'stem_rust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_confusion_matrix(cm, title='Confusion matrix',figsize=None, cmap=plt.cm.Reds, labels=[]):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    \n",
    "    plt.title(title,fontsize=14)\n",
    "    plt.colorbar()\n",
    "    labels = classes\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, fontsize=12,rotation=45)\n",
    "    plt.yticks(tick_marks, labels, fontsize=12 ,rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('Predicted label',fontsize=13)\n",
    "    plt.ylabel('True label',fontsize=13)\n",
    "#    plt.savefig('confusionmatrix_figs/'+title+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Images  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = clean_testloader\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "# call test function    \n",
    "test(testloader, model_transfer, criterion_transfer, use_cuda)\n",
    "\n",
    "actual_label=[]\n",
    "for arr in actual:\n",
    "    for l in arr:\n",
    "        actual_label.append(l)\n",
    "actual_label\n",
    "target_label=[]\n",
    "for arr in predicted:\n",
    "    for l in arr:\n",
    "        target_label.append(l)\n",
    "        \n",
    "y_true = actual_label\n",
    "y_pred = target_label\n",
    "target_names = classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Final Test Accuracy', accuracy_score(y_true, y_pred))\n",
    "plot_confusion_matrix(cm, title = 'Clean Images',figsize=(4.5,3.5))\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "# print('Final Test Accuracy', accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blur Images  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = blur_testloader\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "# call test function    \n",
    "test(testloader, model_transfer, criterion_transfer, use_cuda)\n",
    "\n",
    "actual_label=[]\n",
    "for arr in actual:\n",
    "    for l in arr:\n",
    "        actual_label.append(l)\n",
    "actual_label\n",
    "target_label=[]\n",
    "for arr in predicted:\n",
    "    for l in arr:\n",
    "        target_label.append(l)\n",
    "\n",
    "y_true = actual_label\n",
    "y_pred = target_label\n",
    "target_names = classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Final Test Accuracy', accuracy_score(y_true, y_pred))\n",
    "plot_confusion_matrix(cm, title = 'Blur Images',figsize=(4.5,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised DeBlur Images  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deblur_testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e06074e04b6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeblur_testloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# call test function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deblur_testloader' is not defined"
     ]
    }
   ],
   "source": [
    "testloader = deblur_testloader\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "# call test function    \n",
    "test(testloader, model_transfer, criterion_transfer, use_cuda)\n",
    "\n",
    "actual_label=[]\n",
    "for arr in actual:\n",
    "    for l in arr:\n",
    "        actual_label.append(l)\n",
    "actual_label\n",
    "target_label=[]\n",
    "for arr in predicted:\n",
    "    for l in arr:\n",
    "        target_label.append(l)\n",
    "        \n",
    "        \n",
    "y_true = actual_label\n",
    "y_pred = target_label\n",
    "target_names = classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Final Test Accuracy', accuracy_score(y_true, y_pred))\n",
    "\n",
    "plot_confusion_matrix(cm, title = 'Unsupervised',figsize=(4.5,3.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### supervised DeBlur Images  Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = spvd_deblur_testloader\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "# call test function    \n",
    "test(testloader, model_transfer, criterion_transfer, use_cuda)\n",
    "\n",
    "actual_label=[]\n",
    "for arr in actual:\n",
    "    for l in arr:\n",
    "        actual_label.append(l)\n",
    "actual_label\n",
    "target_label=[]\n",
    "for arr in predicted:\n",
    "    for l in arr:\n",
    "        target_label.append(l)\n",
    "        \n",
    "        \n",
    "y_true = actual_label\n",
    "y_pred = target_label\n",
    "target_names = classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plot_confusion_matrix(cm, title = 'Supervised',figsize=(4.5,3.5))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "print('Final Test Accuracy', accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
