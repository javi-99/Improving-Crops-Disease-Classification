{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils import proc\n",
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_blur(images, kernels, nstd=2, seeds=None):\n",
    "    '''\n",
    "    Input a list of 3d tensors for images and kernels\n",
    "    '''\n",
    "    nstd = nstd / 255.\n",
    "\n",
    "    bsz, h, w, c = tf.convert_to_tensor(images).get_shape().as_list()\n",
    "    kbsz, kh, kw, kc = tf.convert_to_tensor(kernels).get_shape().as_list()\n",
    "    assert kbsz==bsz and kc==1\n",
    "\n",
    "    images = tf.transpose(images, [1,2,0,3]) # h x w x bsz x c\n",
    "    images = tf.reshape(images, [1,h,w,bsz*c])\n",
    "\n",
    "    kernels = tf.tile(kernels, [1,1,1,c])\n",
    "    kernels= tf.transpose(kernels, [1,2,0,3]) # kh x kw x bsz x c\n",
    "    kernels = tf.reshape(kernels, [kh,kw,bsz*c,1])\n",
    "\n",
    "    padding = [[0,0], [(kh-1)//2,(kh-1)//2], [(kw-1)//2, (kw-1)//2], [0,0]]\n",
    "    images = tf.pad(images, padding, 'REFLECT')\n",
    "    blurs = tf.nn.depthwise_conv2d(images, kernels, [1,1,1,1], 'VALID') # 1 x h x w x bsz*c\n",
    "\n",
    "    blurs = tf.reshape(blurs, [h,w,bsz,c])\n",
    "    blurs = tf.transpose(blurs, [2,0,1,3])\n",
    "\n",
    "    if nstd != 0:\n",
    "        if seeds is None:\n",
    "            noise = tf.random_normal([bsz,h,w,c],stddev=nstd)\n",
    "        else:\n",
    "            noise = []\n",
    "            for i in range(bsz):\n",
    "                n = tf.contrib.stateless.stateless_random_normal([h,w,c], seeds[i], dtype=tf.float32) * nstd\n",
    "                noise.append(n)\n",
    "            noise = tf.stack(noise)\n",
    "\n",
    "        blurs = blurs + noise\n",
    "\n",
    "    return blurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Test Image Paths and Corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'test_data/test\n",
    "path = data_root\n",
    "\n",
    "##################################### getting files paths in each folder ##############################\n",
    "## get folder paths\n",
    "folders_paths = []\n",
    "for entry_name in os.listdir(path):\n",
    "    entry_path =  os.path.join(path, entry_name)\n",
    "    if os.path.isdir(entry_path):\n",
    "        folders_paths.append(entry_path)\n",
    "\n",
    "# catch Folder names into list\n",
    "foldernames = []\n",
    "for entry_name in os.listdir(path):\n",
    "    entry_path = os.path.join(path, entry_name)\n",
    "    if os.path.isdir(entry_path):\n",
    "        foldernames.append(entry_name)\n",
    "\n",
    "#print(foldernames)\n",
    "\n",
    "### defining dataframe to store every example into csv againt its class\n",
    "columns = ['image_path','image_id','label']\n",
    "test_dfrm1 = pd.DataFrame(columns=columns)\n",
    "#train.loc[0] = [4,5]\n",
    "\n",
    "## files names into a list with associated label\n",
    "#image_path = folder_paths[1]\n",
    "\n",
    "#rgb_frames = []\n",
    "i = 0\n",
    "fold_ind =0\n",
    "for ind,folder in enumerate(folders_paths):\n",
    "    for image_name in os.listdir(folder):\n",
    "        image_path = os.path.join(folder,image_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            test_dfrm1.loc[i]=[image_path,image_name,foldernames[ind]]\n",
    "            i=i+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = test_dfrm1['image_path']              # extracting image path\n",
    "img_labels = test_dfrm1['label']                # extracting image label\n",
    "img_Ids = test_dfrm1['image_id']             # extracting image_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Blur Kernels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_root = 'blur_kernels'\n",
    "path = data_root\n",
    "\n",
    "##################################### getting path of each kernal ##############################\n",
    "### defining dataframe to store every example into csv againt its class\n",
    "kernel_paths = glob.glob(path+'/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahad/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blur = scipy.misc.imread(kernel_paths[0])\n",
    "ker_shp = blur.shape\n",
    "ker_shp[0],ker_shp[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bluring Images and storing into seperate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahad/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/home/fahad/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
      "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n",
      "  del sys.path[0]\n",
      "/home/fahad/miniconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n"
     ]
    }
   ],
   "source": [
    "data_root_blur = 'test_data/val_128/blur_imgs'\n",
    "data_root_clean = 'test_data/val_128/clean_imgs'\n",
    "set_resize = 128\n",
    "#kernel_shape = 17\n",
    "i = 0\n",
    "for image,folder in zip(img_paths,img_labels):\n",
    "    dest_lab_blur_dir = os.path.join(data_root_blur,folder)\n",
    "    dest_lab_clean_dir = os.path.join(data_root_clean,folder)\n",
    "    if not os.path.exists(dest_lab_blur_dir):\n",
    "        os.makedirs(dest_lab_blur_dir)\n",
    "    if not os.path.exists(dest_lab_clean_dir):\n",
    "        os.makedirs(dest_lab_clean_dir)\n",
    "    v = scipy.misc.imresize(scipy.misc.imread(image),(set_resize,set_resize)).reshape(1,set_resize,set_resize,3).astype('float32')/255\n",
    "    img_clean =load_img(image)\n",
    "    img_clean = img_clean.resize((set_resize, set_resize))    \n",
    "    img_clean.save(os.path.join(dest_lab_clean_dir,str(i)+'.jpg'))\n",
    "    idx = random.randrange(0,len(kernel_paths))\n",
    "    blur = scipy.misc.imread(kernel_paths[idx])\n",
    "    ker_shp = blur.shape\n",
    "    blur = blur.reshape(1,ker_shp[0],ker_shp[1],1).astype('float32')\n",
    "    blur = blur/np.sum(blur)\n",
    "    left_blurs = gen_blur(v, blur, nstd=2, seeds=None)\n",
    "    sess = tf.Session()\n",
    "    array = left_blurs.eval(session=sess)\n",
    "    #im = Image.fromarray(array[0,:,:,:])\n",
    "    #im.save(os.path.join(dest_lab_dir,str(i)+'.jpg'))\n",
    "    plt.imsave(os.path.join(dest_lab_blur_dir,str(i)+'.jpg'),np.clip(array[0,:,:,:],0,1))\n",
    "    i=i+1     \n",
    "    \n",
    "    \n",
    "    #image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debluring images  by trained deblur model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_path = 'wts/supervised'      # set the path where you have saved deblur training\n",
    "\n",
    "from utils import utils as ut\n",
    "from utils import pix as net\n",
    "\n",
    "if trained_path.endswith('.npz'):\n",
    "    mfile = trained_path\n",
    "else:\n",
    "    wts = trained_path\n",
    "    msave = ut.ckpter(wts + '/iter_*.model.npz')\n",
    "    mfile = msave.latest\n",
    "\n",
    "# if out_path is not None:\n",
    "#     if not os.path.exists(out_path):\n",
    "#         os.makedirs(out_path)\n",
    "def csave(fn,img):\n",
    "    img = np.maximum(0.,np.minimum(1.,img))\n",
    "    img = np.uint8(img*255.)\n",
    "    imsave(fn,img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################## getting Paths of blur Images ########################3\n",
    "data_root_blur = 'test_data/val_128/blur_imgs'\n",
    "data_dir = data_root_blur\n",
    "# getting folder paths\n",
    "folder_paths = []\n",
    "folder_names = []\n",
    "for fold_name in os.listdir(data_dir):\n",
    "    fold_path = os.path.join(data_dir,fold_name)\n",
    "    if os.path.isdir(fold_path):\n",
    "        folder_paths.append(fold_path)\n",
    "        folder_names.append(fold_name)\n",
    "\n",
    "## defining dataframe to store every example into csv\n",
    "columns =  ['img_id','img_path','label']\n",
    "blr_dfrm = pd.DataFrame(columns=columns)\n",
    "i = 0\n",
    "fold_ind = 0\n",
    "for ind,folder in enumerate(folder_paths):\n",
    "    for img_name in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        if os.path.isfile(img_path):\n",
    "            blr_dfrm.loc[i]=[img_name,img_path,folder_names[ind]]\n",
    "            i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Build Graph\n",
    "BSZ = len(blr_dfrm)\n",
    "names, blurs = [], []\n",
    "for i in range(BSZ):\n",
    "    nm = tf.placeholder(tf.string)\n",
    "    blur = tf.read_file(nm)\n",
    "    blur = tf.image.decode_png(blur, channels=3, dtype=tf.uint8)\n",
    "    blur = tf.to_float(blur) / 255.\n",
    "    names.append(nm)\n",
    "    blurs.append(blur)\n",
    "blurs = tf.stack(blurs, axis=0)\n",
    "\n",
    "is_training = tf.placeholder_with_default(False, shape=[])\n",
    "model = net.Net(is_training)\n",
    "deblur = blurs + model.generate(blurs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=4))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model from wts/supervised/iter_024000.model.npz\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "print(\"Restoring model from \" + mfile )\n",
    "ut.loadNet(mfile,model.weights,sess)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = blr_dfrm['img_path']\n",
    "labels = blr_dfrm['label']\n",
    "fd= dict(zip(names,img_paths.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run for deblur\n",
    "noisy, preds = sess.run([blurs, deblur], feed_dict=fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<00:00, 585.82it/s]\n"
     ]
    }
   ],
   "source": [
    "data_root_deblur = 'test_data/val_128/deblur_spvd_imgs'\n",
    "labels = blr_dfrm['label']\n",
    "i=0\n",
    "for folder in tqdm(labels):\n",
    "    dest_deblur_dir = os.path.join(data_root_deblur,folder)\n",
    "    if not os.path.exists(dest_deblur_dir):\n",
    "        os.makedirs(dest_deblur_dir)\n",
    "    image_pth = os.path.join(dest_deblur_dir, blr_dfrm['img_id'].values[i])\n",
    "    arr = np.clip(preds[i], 0, 1)\n",
    "    plt.imsave(image_pth,arr)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
